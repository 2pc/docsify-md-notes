"use strict";
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (Object.hasOwnProperty.call(mod, k)) result[k] = mod[k];
    result["default"] = mod;
    return result;
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
const yargs = __importStar(require("yargs"));
const markdown_it_1 = __importDefault(require("markdown-it"));
const fs = __importStar(require("fs"));
const path = __importStar(require("path"));
let args = yargs
    .wrap(yargs.terminalWidth() - 1)
    .usage("$0 [-d docDir] [-s sideBar] ")
    .options({
    sidebar: {
        alias: "s",
        type: "string",
        describe: "The sidebar to index",
        default: "_sidebar.md"
    },
    docDir: {
        alias: "d",
        type: "string",
        describe: "The root directory where the files can be found",
        default: "_sidebar.md"
    },
    output: {
        alias: "o",
        type: "string",
        describe: "The output index json",
        default: "search.json"
    }
}).argv;
function iterate(items, fn) {
    for (let item of items) {
        fn(item);
        if (item.children)
            iterate(item.children, fn);
    }
}
function maybeRead(path) {
    try {
        return fs.readFileSync(path, "utf8");
    }
    catch (e) {
        return e;
    }
}
console.log("Reading", args.sidebar);
let md = new markdown_it_1.default();
let sidebarFile = path.resolve(args.docDir, args.sidebar);
let ast = md.parse(fs.readFileSync(sidebarFile, "utf8"), {});
let links = [];
iterate(ast, token => {
    if (token.type === "link_open")
        links.push(token.attrs.find(a => a[0] === "href")[1]);
});
let indexerDocs = links.flatMap(l => {
    let f = maybeRead(path.resolve(args.docDir, "." + l));
    if (typeof f !== "string")
        return [];
    let innerAst = md.parse(f, {});
    let indexableHeadings = [];
    let state = "begin";
    for (let token of innerAst) {
        if (token.type === "heading_open") {
            indexableHeadings.push({
                file: l,
                title: "",
                content: ""
            });
            state = "heading";
        }
        else if (token.type === "heading_close") {
            state = "content";
        }
        let current = indexableHeadings[indexableHeadings.length - 1];
        if (!current)
            continue;
        if (state == "heading" && token.content.length > 0)
            current.title += token.content;
        else if (state == "content" && token.content.length > 0)
            current.content += token.content + " ";
    }
    return indexableHeadings;
});
// lunr.tokenizer.separator = /\W+/;
// let idx = lunr.default(builder => {
//   builder.field("title", {
//     boost: 2
//   });
//   builder.field("content");
//   builder.metadataWhitelist = ["position"];
//   for (let doc of indexerDocs) builder.add(doc);
// });
// for (let result of idx.search("database")) {
//   console.log(JSON.stringify(result));
// }
let output = JSON.stringify(indexerDocs);
let outFile = path.resolve(args.docDir, args.output);
console.log("Writing search extraction to ", outFile);
fs.writeFileSync(outFile, output);
